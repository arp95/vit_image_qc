{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Header files loaded!\n"
     ]
    }
   ],
   "source": [
    "# header files\n",
    "%matplotlib inline\n",
    "import torch\n",
    "import numpy as np\n",
    "import csv\n",
    "import glob\n",
    "import math\n",
    "import tensorboard\n",
    "from PIL import Image\n",
    "import skimage\n",
    "from skimage import io, transform\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import glob\n",
    "import csv\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [15, 15]\n",
    "print(\"Header files loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/jupyter-arpit@broadinstitu-ef612/code/misc/QC_Image.csv']\n"
     ]
    }
   ],
   "source": [
    "# cpa features for the training dataset\n",
    "files = glob.glob(\"/home/jupyter-arpit@broadinstitu-ef612/code/misc/*.csv\")\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2060\n",
      "2060\n",
      "400\n",
      "400\n",
      "560\n",
      "600\n",
      "350\n",
      "550\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "# get the cpa features for the training and validation dataset\n",
    "X_train = []\n",
    "Y_train = []\n",
    "X_val = []\n",
    "Y_val = []\n",
    "train_count_good = 0\n",
    "train_count_blur = 0\n",
    "train_count_empty = 0\n",
    "train_count_debris = 0\n",
    "val_count_good = 0\n",
    "val_count_blur = 0\n",
    "val_count_empty = 0\n",
    "val_count_debris = 0\n",
    "for file in files:\n",
    "    \n",
    "    flag = -1\n",
    "    with open(file, newline='') as csvfile:\n",
    "        spamreader = csv.reader(csvfile)\n",
    "        for row in spamreader:\n",
    "            if flag == -1:\n",
    "                array = row\n",
    "                flag = 1\n",
    "            else:\n",
    "                array = row\n",
    "                \n",
    "                file = array[35]\n",
    "                if \"train\" in file:\n",
    "                    # feature vector\n",
    "                    train_sample = []\n",
    "                    for index in range(12, 33):\n",
    "                        train_sample.append(array[index])\n",
    "                    X_train.append(train_sample)\n",
    "                    \n",
    "                    # label\n",
    "                    if \"good\" in file:\n",
    "                        Y_train.append(0)\n",
    "                        train_count_good += 1\n",
    "                    elif \"blur\" in file:\n",
    "                        Y_train.append(1)\n",
    "                        train_count_blur += 1\n",
    "                    elif \"empty\" in file:\n",
    "                        Y_train.append(2)\n",
    "                        train_count_empty += 1\n",
    "                    else:\n",
    "                        Y_train.append(3)\n",
    "                        train_count_debris += 1\n",
    "                else:\n",
    "                    # feature vector\n",
    "                    val_sample = []\n",
    "                    for index in range(12, 33):\n",
    "                        val_sample.append(array[index])\n",
    "                    X_val.append(val_sample)\n",
    "                    \n",
    "                    # label\n",
    "                    if \"good\" in file:\n",
    "                        Y_val.append(0)\n",
    "                        val_count_good += 1\n",
    "                    elif \"blur\" in file:\n",
    "                        Y_val.append(1)\n",
    "                        val_count_blur += 1\n",
    "                    elif \"empty\" in file:\n",
    "                        Y_val.append(2)\n",
    "                        val_count_empty += 1\n",
    "                    else:\n",
    "                        Y_val.append(3)\n",
    "                        val_count_debris += 1\n",
    "                        \n",
    "\n",
    "print(len(X_train))\n",
    "print(len(Y_train))\n",
    "print(len(X_val))\n",
    "print(len(Y_val))\n",
    "print(train_count_good)\n",
    "print(train_count_blur)\n",
    "print(train_count_empty)\n",
    "print(train_count_debris)\n",
    "print(val_count_good)\n",
    "print(val_count_blur)\n",
    "print(val_count_empty)\n",
    "print(val_count_debris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random-forest classifier\n",
    "rfc = RandomForestClassifier(n_estimators=100)\n",
    "rfc.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,\n",
       "                   n_estimators=50, random_state=None)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ada-boost classifier\n",
    "rfc = AdaBoostClassifier()\n",
    "rfc.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
       "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "                           max_features=None, max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=1, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                           n_iter_no_change=None, presort='deprecated',\n",
       "                           random_state=None, subsample=1.0, tol=0.0001,\n",
       "                           validation_fraction=0.1, verbose=0,\n",
       "                           warm_start=False)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gradient boosting classifier\n",
    "rfc = GradientBoostingClassifier()\n",
    "rfc.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1\n",
      " 1 1 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 0 0 3 3 3 3 3 3 3 3 1 1 1 3 3 1 1 1 1 1 3 3 3 0 3 1 0 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 1 3 3 3 3 3 1 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 0 3 3 3 3 3 3 3 3 3 3 0 3 3 3 0 3 3 3 3 3 3 3 3 3 3 3 0 3 2 3 3 3\n",
      " 3 3 3 0 3 2 3 0 3 3 3 3 0 3 3 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 0 2 2 2 2 2 2 2 2 2 2 3 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 0 2 2 2 2 2 2 2 3 2 2 2 2 2\n",
      " 2 2 2 2 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 3 0 3 0 0 0 0 0 0 3 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 3 0\n",
      " 0 3 0 0 0 0 0 3 2 0 0 0 0 0 3 0 0 0 0 0 0 1 3 0 2 3 0 3 1 3]\n"
     ]
    }
   ],
   "source": [
    "# prediction on validation dataset\n",
    "pred = rfc.predict(X_val)\n",
    "print(pred)\n",
    "print(Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "342\n"
     ]
    }
   ],
   "source": [
    "# accuracy and cofusion matrix on validation dataset\n",
    "correct = 0\n",
    "for index in range(0, 400):\n",
    "    if pred[index] == Y_val[index]:\n",
    "        correct += 1\n",
    "print(correct)\n",
    "print(confusion_matrix(Y_val, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17277\n"
     ]
    }
   ],
   "source": [
    "# test dataset\n",
    "files = glob.glob(\"/dgx1nas1/cellpainting-datasets/2019_07_11_JUMP_CP_pilots/workspace/qc/2021_03_03_Stain5_CondC_PE_Standard/results/*/*/*_Image.csv\")\n",
    "print(len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86385\n",
      "86385\n"
     ]
    }
   ],
   "source": [
    "test_files = []\n",
    "X_test = []\n",
    "for file in files:\n",
    "    \n",
    "    flag = -1\n",
    "    indexes_dna = []\n",
    "    indexes_rna = []\n",
    "    indexes_er = []\n",
    "    indexes_agp = []\n",
    "    indexes_mito = []\n",
    "    index_filedna = -1\n",
    "    index_filerna = -1\n",
    "    index_fileer = -1\n",
    "    index_fileagp = -1\n",
    "    index_filemito = -1\n",
    "    with open(file, newline='') as csvfile:\n",
    "        spamreader = csv.reader(csvfile)\n",
    "        for row in spamreader:\n",
    "            if flag == -1:\n",
    "                array = row\n",
    "                flag = 1\n",
    "                for index in range(0, len(array)):\n",
    "                    if \"URL_OrigDNA\" in array[index]:\n",
    "                        index_filedna = index\n",
    "                    if \"URL_OrigRNA\" in array[index]:\n",
    "                        index_filerna = index\n",
    "                    if \"URL_OrigER\" in array[index]:\n",
    "                        index_fileer = index\n",
    "                    if \"URL_OrigMito\" in array[index]:\n",
    "                        index_filemito = index\n",
    "                    if \"URL_OrigAGP\" in array[index]:\n",
    "                        index_fileagp = index\n",
    "                        \n",
    "                        \n",
    "                    # append dna features\n",
    "                    if \"OrigDNA\" in array[index] and \"ImageQuality\" in array[index]:\n",
    "                        indexes_dna.append(index)\n",
    "                    \n",
    "                    # append rna features\n",
    "                    if \"OrigRNA\" in array[index] and \"ImageQuality\" in array[index]:\n",
    "                        indexes_rna.append(index)\n",
    "                        \n",
    "                    # append er features\n",
    "                    if \"OrigER\" in array[index] and \"ImageQuality\" in array[index]:\n",
    "                        indexes_er.append(index)\n",
    "                        \n",
    "                    # append agp features\n",
    "                    if \"OrigAGP\" in array[index] and \"ImageQuality\" in array[index]:\n",
    "                        indexes_agp.append(index)\n",
    "                        \n",
    "                    # append mito features\n",
    "                    if \"OrigMito\" in array[index] and \"ImageQuality\" in array[index]:\n",
    "                        indexes_mito.append(index)\n",
    "            else:\n",
    "                array = row\n",
    "                \n",
    "                # dna file\n",
    "                if index_filedna >= 0:\n",
    "                    file_dna = \"/dgx1nas1/cellpainting-datasets/\"\n",
    "                    sample = array[index_filedna].split(\"/\")\n",
    "                    for index in range(5, len(sample)):\n",
    "                        file_dna = file_dna + sample[index]\n",
    "                        file_dna = file_dna + \"/\"\n",
    "                    file_dna = file_dna.replace(\"2019_07_11_JUMP-CP-pilots\", \"2019_07_11_JUMP_CP_pilots\")\n",
    "                    test_files.append(file_dna[:len(file_dna)-1])\n",
    "                    \n",
    "                    sample_dna = []\n",
    "                    for index in range(0, len(indexes_dna)):\n",
    "                        sample_dna.append(array[indexes_dna[index]])\n",
    "                    X_test.append(sample_dna)\n",
    "                    \n",
    "                # rna file\n",
    "                if index_filerna >= 0:\n",
    "                    file_rna = \"/dgx1nas1/cellpainting-datasets/\"\n",
    "                    sample = array[index_filerna].split(\"/\")\n",
    "                    for index in range(5, len(sample)):\n",
    "                        file_rna = file_rna + sample[index]\n",
    "                        file_rna = file_rna + \"/\"\n",
    "                    file_rna = file_rna.replace(\"2019_07_11_JUMP-CP-pilots\", \"2019_07_11_JUMP_CP_pilots\")\n",
    "                    test_files.append(file_rna[:len(file_rna)-1])\n",
    "                    \n",
    "                    sample_rna = []\n",
    "                    for index in range(0, len(indexes_rna)):\n",
    "                        sample_rna.append(array[indexes_rna[index]])\n",
    "                    X_test.append(sample_rna)\n",
    "                    \n",
    "                # er file\n",
    "                if index_fileer >= 0:\n",
    "                    file_er = \"/dgx1nas1/cellpainting-datasets/\"\n",
    "                    sample = array[index_fileer].split(\"/\")\n",
    "                    for index in range(5, len(sample)):\n",
    "                        file_er = file_er + sample[index]\n",
    "                        file_er = file_er + \"/\"\n",
    "                    file_er = file_er.replace(\"2019_07_11_JUMP-CP-pilots\", \"2019_07_11_JUMP_CP_pilots\")\n",
    "                    test_files.append(file_er[:len(file_er)-1])\n",
    "                    \n",
    "                    sample_er = []\n",
    "                    for index in range(0, len(indexes_er)):\n",
    "                        sample_er.append(array[indexes_er[index]])\n",
    "                    X_test.append(sample_er)\n",
    "                    \n",
    "                # agp file\n",
    "                if index_fileagp >= 0:\n",
    "                    file_agp = \"/dgx1nas1/cellpainting-datasets/\"\n",
    "                    sample = array[index_fileagp].split(\"/\")\n",
    "                    for index in range(5, len(sample)):\n",
    "                        file_agp = file_agp + sample[index]\n",
    "                        file_agp = file_agp + \"/\"\n",
    "                    file_agp = file_agp.replace(\"2019_07_11_JUMP-CP-pilots\", \"2019_07_11_JUMP_CP_pilots\")\n",
    "                    test_files.append(file_agp[:len(file_agp)-1])\n",
    "                    \n",
    "                    sample_agp = []\n",
    "                    for index in range(0, len(indexes_agp)):\n",
    "                        sample_agp.append(array[indexes_agp[index]])\n",
    "                    X_test.append(sample_agp)\n",
    "                    \n",
    "                # mito file\n",
    "                if index_filemito >= 0:\n",
    "                    file_mito = \"/dgx1nas1/cellpainting-datasets/\"\n",
    "                    sample = array[index_filemito].split(\"/\")\n",
    "                    for index in range(5, len(sample)):\n",
    "                        file_mito = file_mito + sample[index]\n",
    "                        file_mito = file_mito + \"/\"\n",
    "                    file_mito = file_mito.replace(\"2019_07_11_JUMP-CP-pilots\", \"2019_07_11_JUMP_CP_pilots\")\n",
    "                    test_files.append(file_mito[:len(file_mito)-1])\n",
    "                    \n",
    "                    sample_mito = []\n",
    "                    for index in range(0, len(indexes_mito)):\n",
    "                        sample_mito.append(array[indexes_mito[index]])\n",
    "                    X_test.append(sample_mito)\n",
    "print(len(X_test))\n",
    "print(len(test_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "pred = rfc.predict(X_test)\n",
    "pred_prob = rfc.predict_proba(X_test)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63468\n",
      "0\n",
      "66\n",
      "22851\n"
     ]
    }
   ],
   "source": [
    "count_good = 0\n",
    "count_blur = 0\n",
    "count_empty = 0\n",
    "count_debris = 0\n",
    "for index in range(0, len(pred)):\n",
    "    if pred[index] == 0:\n",
    "        count_good += 1\n",
    "    elif pred[index] == 1:\n",
    "        count_blur += 1\n",
    "    elif pred[index] == 2:\n",
    "        count_empty += 1\n",
    "    elif pred[index] == 3:\n",
    "        count_debris += 1\n",
    "\n",
    "print(count_good)\n",
    "print(count_blur)\n",
    "print(count_empty)\n",
    "print(count_debris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "filename = 'qc_bestmodel_cpa.sav'\n",
    "pickle.dump(rfc, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "rfc = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30548\n"
     ]
    }
   ],
   "source": [
    "# write results\n",
    "count = 0\n",
    "with open(\"test_baseline_cpa_only_bad.csv\", 'w', newline='') as csvfile:\n",
    "    spamwriter = csv.writer(csvfile)\n",
    "    spamwriter.writerow([\"File Path\", \"Good Probability\", \"Blurry Probability\", \"Empty Probability\", \"Debris Probability\", \"Label\"])\n",
    "    for index in range(0, len(pred)):\n",
    "        if pred[index] == 1 or pred[index] == 2 or pred[index] == 3:\n",
    "            count += 1\n",
    "            spamwriter.writerow([test_files[index], pred_prob[index][0], pred_prob[index][1], pred_prob[index][2], pred_prob[index][3], pred[index]])\n",
    "print(count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
