---
title: "Inspect test dataset structure"
output: html_notebook
params:
  dataset: Stain5_CondC_PE_Standard
  metadata:
    value:
      r_start: 2
      r_end: 3
      c_start: 5
      c_end: 6
      f_start: 8
      f_end: 9
      ch_start: 16
      ch_end: 16
  split_string:
    value: 
    - x1
    - x2
    - x3
    - project
    - batch
    - x
    - plate
    - x5
    - image
        
--- 

```{r}
library(glue)
library(tidyverse)
```

```{r}
dataset <- params$dataset
metadata <- params$metadata
split_string <- params$split_string
```

```{r}
read_test_result <- function(filename) {
  test_result <- read_csv(
    filename,
    col_types = cols(
      `File Path` = col_character(),
      `Good Probability` = col_double(),
      `Blurry Probability` = col_double(),
      `Empty Probability` = col_double(),
      `Debris Probability` = col_double(),
      Label = col_double()
    )
  )
  
  test_result <-
    test_result %>%
    rename(
      file = `File Path`,
      good = `Good Probability`,
      blurry = `Blurry Probability`,
      empty = `Empty Probability`,
      debris = `Debris Probability`,
      label = Label
    ) %>%
    separate(
      file,
      split_string,
      sep = "/",
      extra = "merge"
    ) %>%
    select(-matches("^x")) %>%
    mutate(plate = str_sub(plate, 1, 10))
  
  test_result <-
    test_result %>%
    mutate(
      r = str_sub(image, metadata$r_start, metadata$r_end),
      c = as.integer(str_sub(
        image, metadata$c_start, metadata$c_end
      )),
      f = as.integer(str_sub(
        image, metadata$f_start, metadata$f_end
      )),
      ch = as.integer(str_sub(
        image, metadata$ch_start, metadata$ch_end
      )),
      .after = image
    ) %>%
    mutate(r = ifelse(grepl("^[0-9]+$", r), as.integer(r), r))
  
  test_result
  
}
```


```{r}
check_duplicates <- function(df) {
  df %>%
    count(plate, r, c, f, ch) %>%
    filter(n > 1)
}
```


```{r}
test_baseline <- read_test_result(glue("input/{dataset}/test_baseline.csv.gz"))

test_baseline_cpa <- read_test_result(glue("input/{dataset}/test_baseline_cpa.csv.gz"))

test_transformer <- read_test_result(glue("input/{dataset}/test_transformer.csv.gz"))
```


```{r}
check_duplicates(test_baseline)

check_duplicates(test_baseline_cpa)

check_duplicates(test_transformer)
```
```{r}
regularize <- function(df) {
  df %>% select(-(good:label)) %>% 
    arrange(across(everything()))
}

compare::compare(regularize(test_transformer),
                 regularize(test_baseline))
compare::compare(regularize(test_transformer),
                 regularize(test_baseline_cpa))
```

```{r}
test_transformer %>%
  count(plate)
```


```{r}
test_transformer %>%
  count(r)
```


```{r}
test_transformer %>%
  count(c)
```


```{r}
test_transformer %>%
  count(f)
```


```{r}
test_transformer %>%
  count(ch)
```

Field 1 is missing

```{r}
test_transformer %>%
  filter(plate == "BR00120275__2021-02-20T14_16_02-Measurement1") %>%
  count(plate, r, c) %>%
  filter(n != 45) %>%
  inner_join(test_transformer) %>%
  count(f)
```

The rest looks good!

Combine them all

```{r}
test_dataset <-
  rbind(
    test_baseline %>% mutate(classifier = "baseline", .before = project),
    test_baseline_cpa %>% mutate(classifier = "baseline_cpa", .before = project),
    test_transformer %>% mutate(classifier = "transformer", .before = project)
  )
```

```{r}
test_dataset %>% arrow::write_parquet(glue("input/{dataset}/test_dataset.parquet"))
```

